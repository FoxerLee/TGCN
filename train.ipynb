{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import optimizers\n",
    "from sklearn import metrics\n",
    "\n",
    "from utils.utils import *\n",
    "from models.gcn import GCN\n",
    "\n",
    "from config import CONFIG\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set genral parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "cfg = CONFIG()\n",
    "\n",
    "# set random seed\n",
    "seed = 6606\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'R8'\n",
    "cfg.dataset = dataset  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj, features, y_train, y_val, y_test, train_mask, val_mask, test_mask, train_size, test_size = load_corpus(cfg.dataset)\n",
    "\n",
    "features = sp.identity(features.shape[0])  # featureless\n",
    "features = preprocess_features(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate features, labels, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "support = [preprocess_adj(adj)]\n",
    "\n",
    "\n",
    "t_features = tf.SparseTensor(*features)\n",
    "t_y_train = tf.convert_to_tensor(y_train)\n",
    "t_y_val = tf.convert_to_tensor(y_val)\n",
    "t_y_test = tf.convert_to_tensor(y_test)\n",
    "tm_train_mask = tf.convert_to_tensor(train_mask)\n",
    "\n",
    "tm_val_mask = tf.convert_to_tensor(val_mask)\n",
    "tm_test_mask = tf.convert_to_tensor(test_mask)\n",
    "\n",
    "t_support = []\n",
    "for i in range(len(support)):\n",
    "    t_support.append(tf.cast(tf.SparseTensor(*support[i]), dtype=tf.float64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input  dim:  15362\n",
      "output dim:  8\n",
      "WARNING:tensorflow:From /floyd/home/models/layers.py:114: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n"
     ]
    }
   ],
   "source": [
    "model = GCN(input_dim=features[2][1], output_dim=y_train.shape[1], num_features_nonzero=features[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optimizers.Adam(lr=cfg.learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 train_loss= 0.06394 train_acc= 0.98339 val_loss= 0.10886 val_acc= 0.95985 time= 0.62827\n",
      "Epoch: 0002 train_loss= 0.06571 train_acc= 0.98137 val_loss= 0.10808 val_acc= 0.95985 time= 0.62754\n",
      "Epoch: 0003 train_loss= 0.06388 train_acc= 0.98218 val_loss= 0.10799 val_acc= 0.96168 time= 0.62758\n",
      "Epoch: 0004 train_loss= 0.06270 train_acc= 0.98440 val_loss= 0.10890 val_acc= 0.95985 time= 0.63014\n",
      "Epoch: 0005 train_loss= 0.05714 train_acc= 0.98683 val_loss= 0.11019 val_acc= 0.95985 time= 0.63138\n",
      "Epoch: 0006 train_loss= 0.06074 train_acc= 0.98481 val_loss= 0.11198 val_acc= 0.95803 time= 0.62789\n",
      "Epoch: 0007 train_loss= 0.05852 train_acc= 0.98562 val_loss= 0.11471 val_acc= 0.95438 time= 0.62943\n",
      "Epoch: 0008 train_loss= 0.05659 train_acc= 0.98744 val_loss= 0.11766 val_acc= 0.94891 time= 0.63082\n",
      "Epoch: 0009 train_loss= 0.05519 train_acc= 0.98562 val_loss= 0.11946 val_acc= 0.94891 time= 0.62694\n",
      "Epoch: 0010 train_loss= 0.05668 train_acc= 0.98683 val_loss= 0.11915 val_acc= 0.94891 time= 0.62909\n",
      "Epoch: 0011 train_loss= 0.05516 train_acc= 0.98582 val_loss= 0.11759 val_acc= 0.94891 time= 0.63290\n",
      "Epoch: 0012 train_loss= 0.05620 train_acc= 0.98663 val_loss= 0.11461 val_acc= 0.95255 time= 0.62586\n",
      "Early stopping...\n"
     ]
    }
   ],
   "source": [
    "cost_val = []\n",
    "for epoch in range(cfg.epochs):\n",
    "    \n",
    "    t = time.time()\n",
    "    with tf.GradientTape() as tape:\n",
    "        _, loss, acc = model((t_features, t_y_train, tm_train_mask, t_support))\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "    _, val_loss, val_acc = model((t_features, t_y_val, tm_val_mask, t_support), training=False)\n",
    "    cost_val.append(val_loss)\n",
    "    \n",
    "    print(\"Epoch:\", '%04d' % (epoch + 1), \"train_loss=\", \"{:.5f}\".format(loss),\n",
    "          \"train_acc=\", \"{:.5f}\".format(acc), \"val_loss=\", \"{:.5f}\".format(val_loss),\n",
    "          \"val_acc=\", \"{:.5f}\".format(val_acc), \"time=\", \"{:.5f}\".format(time.time() - t))\n",
    "    \n",
    "    if epoch > cfg.early_stopping and cost_val[-1] > np.mean(cost_val[-(cfg.early_stopping+1):-1]):\n",
    "        print(\"Early stopping...\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(features, y, mask, support):\n",
    "    t = time.time()\n",
    "    \n",
    "    pred, test_loss, test_acc = model((features, y, mask, support), training=False)\n",
    "    \n",
    "    \n",
    "    return test_loss, test_acc, pred, np.argmax(y, axis=1), time.time() - t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set results: cost= 0.11257 accuracy= 0.97213 time= 0.11193\n",
      "Average Test Precision, Recall and F1-Score...\n",
      "(0.972133394243947, 0.972133394243947, 0.972133394243947, None)\n"
     ]
    }
   ],
   "source": [
    "test_cost, test_acc, pred, labels, test_duration = evaluate(t_features, t_y_test, tm_test_mask, t_support)\n",
    "print(\"Test set results:\", \"cost=\", \"{:.5f}\".format(test_cost), \"accuracy=\", \"{:.5f}\".format(test_acc), \"time=\", \"{:.5f}\".format(test_duration))\n",
    "\n",
    "\n",
    "test_pred = []\n",
    "test_labels = []\n",
    "\n",
    "for i in range(len(test_mask)):\n",
    "    if test_mask[i]:\n",
    "        test_pred.append(pred[i])\n",
    "        test_labels.append(labels[i])\n",
    "\n",
    "print(\"Average Test Precision, Recall and F1-Score...\")\n",
    "print(metrics.precision_recall_fscore_support(test_labels, test_pred, average='micro'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
